{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import simplejson as json\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of entities\n",
    "entities = [\"COURT\",\"PETITIONER\",\"RESPONDENT\",\"JUDGE\",\"DATE\",\"ORG\",\"GPE\",\"STATUTE\",\"PROVISION\",\"PRECEDENT\",\"CASE_NUMBER\",\"WITNESS\",\"OTHER_PERSON\"]\n",
    "\n",
    "# Generate BIO encoding for each entity\n",
    "bio_encoding = []\n",
    "for entity in entities:\n",
    "    bio_encoding.extend([\"B_\" + entity, \"I_\" + entity])\n",
    "\n",
    "bio_encoding.append(\"O\")\n",
    "\n",
    "def data_formatter(data):\n",
    "    formatted_data = []\n",
    "    for i in data.keys():\n",
    "        formatted_data.append({'text': data[i]['text'], 'labels': data[i]['labels']})\n",
    "    return formatted_data\n",
    "\n",
    "def label_encoder(labels):\n",
    "    encoded_labels = []\n",
    "    for label in labels:\n",
    "        if label in bio_encoding:\n",
    "            encoded_labels.append(bio_encoding.index(label))\n",
    "        else:\n",
    "            encoded_labels.append(bio_encoding.index(\"O\"))\n",
    "    return encoded_labels\n",
    "\n",
    "def tokenize_text(text):\n",
    "    word_to_index = {}\n",
    "    encoded_texts = []\n",
    "    \n",
    "    max_len = 0\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        text[i]['text'] = text[i]['text'].split(' ')\n",
    "        temp = text[i]['text']\n",
    "        encoded_text = [word_to_index.setdefault(word, len(word_to_index)) for word in temp]\n",
    "        max_len = max(max_len, len(encoded_text))\n",
    "        text[i]['text'] = encoded_text\n",
    "        text[i]['labels'] = label_encoder(text[i]['labels'])\n",
    "    \n",
    "    padded_text = []\n",
    "    padded_labels = []\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        padded_text.append(text[i]['text'] + [0] * (max_len - len(text[i]['text'])))\n",
    "        padded_labels.append(text[i]['labels'] + [0] * (max_len - len(text[i]['labels'])))\n",
    "        \n",
    "    return [padded_text, padded_labels]\n",
    "\n",
    "def finalize(text, labels):\n",
    "    input_tensor = torch.tensor(text, dtype=torch.long)\n",
    "    label_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    dataset = TensorDataset(input_tensor, label_tensor)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    with open('../data/NER_train.json', 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "        train_data = data_formatter(train_data)\n",
    "        train_data = tokenize_text(train_data)\n",
    "        \n",
    "    with open('../data/NER_test.json', 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "        test_data = data_formatter(test_data)\n",
    "        test_data = tokenize_text(test_data)\n",
    "        \n",
    "    with open('../data/NER_val.json', 'r') as f:\n",
    "        val_data = json.load(f)\n",
    "        val_data = data_formatter(val_data)\n",
    "        val_data = tokenize_text(val_data)\n",
    "        \n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_data, test_data, val_data = load_dataset()\n",
    "\n",
    "train_dataset = finalize(train_data[0], train_data[1])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = finalize(test_data[0], test_data[1])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = finalize(val_data[0], val_data[1])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained word embeddings\n",
    "word2vec = api.load(\"word2vec-google-news-300\")\n",
    "glove = api.load(\"glove-wiki-gigaword-100\")\n",
    "fasttext = api.load(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the RNN-based models\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, embedding_weights):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_weights))\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        output = self.fc(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, embedding_weights):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_weights))\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, embedding_weights):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_weights))\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.gru(embedded)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 27\n",
    "input_size = 300\n",
    "hidden_size = 128\n",
    "output_size = num_classes\n",
    "num_epochs = 100\n",
    "\n",
    "learning_rate1 = 0.001\n",
    "learning_rate2 = 0.001\n",
    "learning_rate3 = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec(Input_Size = 300, lr = 0.001, 0.01, 0.1)\n",
    "model = RNNModel(input_size, hidden_size, output_size, word2vec.vectors)\n",
    "model2 = LSTMModel(input_size, hidden_size, output_size, word2vec.vectors)\n",
    "model3 = GRUModel(input_size, hidden_size, output_size, word2vec.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# golve(Input_Size = 100, lr = 0.001, 0.001, 0.001)\n",
    "model4 = RNNModel(input_size, hidden_size, output_size, glove.vectors)\n",
    "model5 = LSTMModel(input_size, hidden_size, output_size, glove.vectors)\n",
    "model6 = GRUModel(input_size, hidden_size, output_size, glove.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext(Input_Size = 300, lr = 0.001, 0.001, 0.001)\n",
    "model7 = RNNModel(input_size, hidden_size, output_size, fasttext.vectors)\n",
    "model8 = LSTMModel(input_size, hidden_size, output_size, fasttext.vectors)\n",
    "model9 = GRUModel(input_size, hidden_size, output_size, fasttext.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.Adam(model7.parameters(), lr=learning_rate1)\n",
    "\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = optim.Adam(model8.parameters(), lr=learning_rate2)\n",
    "\n",
    "criterion3 = nn.CrossEntropyLoss()\n",
    "optimizer3 = optim.Adam(model9.parameters(), lr=learning_rate3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, dim=2)\n",
    "            y_true.extend(labels.cpu().numpy().flatten())\n",
    "            y_pred.extend(predicted.cpu().numpy().flatten())\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return macro_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, train_dataloader, num_epochs, criterion, optimizer, output_size, val_dataloader):\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss_mask = (inputs != 0)\n",
    "            loss = criterion(outputs.view(-1, output_size), labels.view(-1))\n",
    "            loss = torch.sum(loss * loss_mask.view(-1)) / torch.sum(loss_mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        if epoch % 5 == 0:\n",
    "            f1_score = evaluate(model, val_dataloader)\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss/len(train_dataloader)}, F1 Score: {f1_score}')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(model, train_dataloader, num_epochs, criterion1, optimizer1, output_size, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = train(model2, train_dataloader, num_epochs, criterion2, optimizer2, output_size, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = train(model3, train_dataloader, num_epochs, criterion3, optimizer3, output_size, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = train(model4, train_dataloader, num_epochs, criterion1, optimizer1, output_size, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = train(model5, train_dataloader, num_epochs, criterion2, optimizer2, output_size, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = train(model6, train_dataloader, num_epochs, criterion3, optimizer3, output_size, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = train(model7, train_dataloader, num_epochs, criterion1, optimizer1, output_size, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = train(model8, train_dataloader, num_epochs, criterion2, optimizer2, output_size, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 0.25081583548827, F1 Score: 0.07314371333907264\n",
      "Epoch [10/100], Loss: 0.18768759796106482, F1 Score: 0.07160366280688156\n",
      "Epoch [15/100], Loss: 0.15555515814112478, F1 Score: 0.07144988881800603\n",
      "Epoch [20/100], Loss: 0.1311136958489855, F1 Score: 0.07312991177635292\n",
      "Epoch [25/100], Loss: 0.10929623771592441, F1 Score: 0.07527247767567134\n",
      "Epoch [30/100], Loss: 0.08981473647443897, F1 Score: 0.07527185442347349\n",
      "Epoch [35/100], Loss: 0.07176251992939478, F1 Score: 0.07686956163169381\n",
      "Epoch [40/100], Loss: 0.0577271441702705, F1 Score: 0.07518539177835812\n",
      "Epoch [45/100], Loss: 0.04653218818227371, F1 Score: 0.07523585140140501\n",
      "Epoch [50/100], Loss: 0.037475224844072445, F1 Score: 0.07563642686383287\n",
      "Epoch [55/100], Loss: 0.029704654444587895, F1 Score: 0.07631801040911054\n",
      "Epoch [60/100], Loss: 0.02466441742125973, F1 Score: 0.0760640506509891\n",
      "Epoch [65/100], Loss: 0.022021214904419453, F1 Score: 0.07508011255616026\n",
      "Epoch [70/100], Loss: 0.016340914920744194, F1 Score: 0.0751396018057439\n",
      "Epoch [75/100], Loss: 0.013651117598971878, F1 Score: 0.07604147892725178\n",
      "Epoch [80/100], Loss: 0.01299870374660746, F1 Score: 0.0752999180135002\n",
      "Epoch [85/100], Loss: 0.008651308364706092, F1 Score: 0.07464586101527448\n",
      "Epoch [90/100], Loss: 0.025876541187860577, F1 Score: 0.07455039362901263\n",
      "Epoch [95/100], Loss: 0.006758997591576016, F1 Score: 0.07389980775129872\n",
      "Epoch [100/100], Loss: 0.014275529087925575, F1 Score: 0.07488698584232745\n"
     ]
    }
   ],
   "source": [
    "model9 = train(model9, train_dataloader, num_epochs, criterion3, optimizer3, output_size, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 score on validation set for model 1: 0.0752215363537528\n",
      "Macro F1 score on validation set for model 2: 0.07324899400924201\n",
      "Macro F1 score on validation set for model 3: 0.07099872944756906\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "macro_f1 = evaluate(model, test_dataloader)\n",
    "print(f'Macro F1 score on validation set for model 1: {macro_f1}')\n",
    "\n",
    "macro_f1 = evaluate(model2, test_dataloader)\n",
    "print(f'Macro F1 score on validation set for model 2: {macro_f1}')\n",
    "\n",
    "macro_f1 = evaluate(model3, test_dataloader)\n",
    "print(f'Macro F1 score on validation set for model 3: {macro_f1}')\n",
    "\n",
    "macro_f1 = evaluate(model4, test_dataloader)\n",
    "print(f'Macro F1 score on validation set for model 4: {macro_f1}')\n",
    "\n",
    "macro_f1 = evaluate(model5, test_dataloader)\n",
    "print(f'Macro F1 score on validation set for model 5: {macro_f1}')\n",
    "\n",
    "macro_f1 = evaluate(model6, test_dataloader)\n",
    "print(f'Macro F1 score on validation set for model 6: {macro_f1}')\n",
    "\n",
    "macro_f1 = evaluate(model7, test_dataloader)\n",
    "print(f'Macro F1 score on validation set for model 7: {macro_f1}')\n",
    "\n",
    "macro_f1 = evaluate(model8, test_dataloader)\n",
    "print(f'Macro F1 score on validation set for model 8: {macro_f1}')\n",
    "\n",
    "macro_f1 = evaluate(model9, test_dataloader)\n",
    "print(f'Macro F1 score on validation set for model 9: {macro_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import os\n",
    "os.makedirs('word2vec', exist_ok=True)\n",
    "os.makedirs('glove', exist_ok=True)\n",
    "os.makedirs('fasttext', exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), 'word2vec/rnn_model.pth')\n",
    "torch.save(model2.state_dict(), 'word2vec/lstm_model.pth')\n",
    "torch.save(model3.state_dict(), 'word2vec/gru_model.pth')\n",
    "\n",
    "torch.save(model4.state_dict(), 'glove/rnn_model.pth')\n",
    "torch.save(model5.state_dict(), 'glove/lstm_model.pth')\n",
    "torch.save(model6.state_dict(), 'glove/gru_model.pth')\n",
    "\n",
    "torch.save(model7.state_dict(), 'fasttext/rnn_model.pth')\n",
    "torch.save(model8.state_dict(), 'fasttext/lstm_model.pth')\n",
    "torch.save(model9.state_dict(), 'fasttext/gru_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
